<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Spike Train Dataset Conversion Tool for Spiking Neural Network Analysis</title>
  
  <!-- Bootstrap -->
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link href="css/custom.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">

  <link href="css/style.css" rel="stylesheet" type="text/css" media="all" />
  <!-- Bootstrap core CSS -->
  <link href="css/css/bootstrap.min.css" rel="stylesheet">


  <style>
    body {
      background: rgb(255, 255, 255) no-repeat fixed top left;
      font-family: 'Open Sans', sans-serif;
    }
  </style>

</head>
<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2>Spike Train Dataset Conversion Tool for Spiking Neural Network Analysis
          </h2>
          <!-- <h4 style="color:#5a6268;">under-review</h4> -->
          <hr>
          <h6>
            <a href="https://github.com/Rao-Sanaullah" target="_blank">Sanaullah</a><sup>1*</sup>,
			<a href="#top">Francisco Barranco</a><sup>2</sup>,
			<a href="#top">Eduardo Ros</a><sup>2</sup>,
			<a href="#top">Ulrich Rückert</a><sup>3</sup>,
            <a href="#top">Thorsten Jungeblut</a><sup>1</sup>
          </h6>
          * Corresponding Author: Sanaullah
          <p>
			<sup>1</sup>Industrial Internet of Things, Hochschule Bielefeld, Germany &nbsp;&nbsp;
            <sup>2</sup>CVR-Lab, University of Granada, Spain &nbsp;&nbsp;
			<sup>3</sup>Cognitronics & Sensor Systems, Universität Bielefeld, Germany
            <br>

          <div class="row justify-content-center">
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light"
                  href="#"
                  role="button" target="_blank">
                  <i class="fa fa-file"></i> Paper (under-review)</a> </p>
            </div>

            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/Rao-Sanaullah/neurocomputing_application_code"
                  role="button" target="_blank">
                  <i class="fa fa-github-alt"></i> Code</a> </p>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<div class="container">
    <div class="row">
	    <section class="hand-crafted">
			<h3 class="w3l_header w3_agileits_header"><span>Abstract</span></h3>
			<div class="col-md-12 wthree_services_grid_left">
                 <p style="text-align: justify;">
		As part of an external lab collaboration (Dataninja project) with Prof. Francisco Barranco and Prof. Eduardo Ros at the Computer Vision and Robotics (CVR) Lab, 
		I worked on an event-based activity recognition dataset developed by the host lab. Our research focuses on Spiking Neural Network (SNN) exploration, where data must be represented as spike trains for effective network processing. 
		To address this issue, I designed and implemented an algorithm that converts the original event-based dataset into spike train format, tailored for SNN applications. In addition to data conversion, 
		I worked on a framework for visualizing and comparing both the original event-based dataset and the generated spike train dataset. This framework allows for the event and spike reconstruction into frame-based visualizations, 
		producing event-based videos from real and spike-based videos from generated datasets. This visualization is essential for validating the fidelity of the spike train dataset by comparing it to the original data. 
		The spike train dataset, along with the visualization framework, is publicly available on our GitHub channel, contributing valuable resources to the SNN research community and advancing the field of event-based vision exploration.</p>
			</div>
		</section>
	</div>
</div>


<!-- WHAT IS RAVSIM OFFERING -->

	<div class="container">
		<div class="col-md-12 wthree_services_grid_right">
			<div class="col-md-12 ">
		
				<div class="clearfix"> </div>
				<br><br>
				<div class="col-md-12 wthree_services_grid_left">
					<h3 class="w3l_header w3_agileits_header">Event Dataset with <span>Spiking Neural Network</span></h3>
					<p style="text-align: justify;"> 
						Event-based vision and SNNs are emerging as transformative technologies for neuromorphic computing, which offers efficient and biologically inspired methods for processing dynamic and real-time data. 
						Traditional frame-based methods struggle to match the temporal resolution and low-latency response offered by event-based sensors, such as Dynamic Vision Sensors (DVS) or DAVIS cameras, 
						which capture changes in the scene at the pixel level. These sensors output asynchronous events rather than static frames, which opens new possibilities for high-speed and low-power applications. 
						However, the use of these event-based datasets in SNNs requires specific data formats, namely spike trains, that mirror the spike-based communication found in biological neural networks.
					</p>
					<br>
					<br>
					<div class="container">
						<div class="row">
							<!-- Text on the right -->
							<div class="col-md-9 wthree_services_grid_left">
								<h3>A Event <span>Dataset</span></h3>
								<p style="text-align: justify;">
									Event-based cameras capture dynamic changes in a scene by recording pixel-level events triggered by motion, rather than traditional frame-based methods: <br>
									1- Timestamp: High-precision time information for each event. <br>
									2- Pixel Coordinates (x, y): Specifies the exact location of the pixel where the event occurred. <br>
									3- Polarity (ON/OFF): Indicates whether the pixel brightness increased or decreased. <br>
									4- Event Intensity: Represents the magnitude of brightness change for some event cameras. <br>
								</p>
							</div>
							<!-- GIF on the left -->
							<div class="col-md-3 wthree_services_grid_right">
								<br>
								<img style="width: 80%;" src="videos/event_event.gif" alt="Event GIF">
							</div>
						</div>
					</div>
					<br>
					<br>
					<div class="container">
						<div class="row">
							<!-- Text on the right -->
							<div class="col-md-9 wthree_services_grid_left">
								<h3>A Spike Train <span>Dataset</span></h3>
								<p style="text-align: justify;">
									Converting event-based datasets to spike trains is essential for SNNs. 
									Spike trains align with SNNs time-based processing, while event-based data, being asynchronous, is difficult for spiking models to handle efficiently. <br>
									Why conversion is important: <br>
									1- Better compatibility: Spike trains match the temporal dynamics of spiking neurons. <br>
									2- Improved processing: Event-based data streams are challenging for spiking models. <br>
									3- Efficient learning: Spike trains enable time-dependent training and inference. <br>
									4- Optimized performance: SNNs work more effectively with spatiotemporal data patterns. <br>
								</p>
							</div>
							<!-- GIF on the left -->
							<div class="col-md-3 wthree_services_grid_right">
								<br>
								<img style="width: 95%;" src="videos/spike_event.gif" alt="Event GIF">
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>









<footer class="text-center" style="margin-bottom:10px; font-size: medium;">
  <hr>
<p>© 2023 IIOT Lab - Hochschule Bielefeld (HSBI). All Rights Reserved | Design by <a href="https://github.com/Rao-Sanaullah">Sanaullah</a></p>
</footer>

</body>

</html>
